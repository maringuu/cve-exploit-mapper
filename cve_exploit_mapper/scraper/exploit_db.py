"""Scrapes information from exploit-db.com
Note that there is no api to do this so the module does many http requests."""

import pandas as pd
from pandas import DataFrame
import requests
import json
import subprocess as sp
from pathlib import Path
import sys
import traceback


def download_to_path(_path):
    path = Path(_path)
    if path.exists():
        sp.run(
            f"GIT_DIR={path}/.git git pull",
            shell=True,
            stdout=sp.DEVNULL,
            stderr=sp.DEVNULL,
            check=True,
        )
    else:
        sp.run(
            f"git clone https://github.com/offensive-security/exploitdb {path}",
            shell=True,
            stdout=sp.DEVNULL,
            stderr=sp.DEVNULL,
            check=True,
        )


def fetch_dataframe(path, delta=None, skip=None):
    """path is the path to the clone of the exploitdb repo.
    delta is DataFrame previously created.
    """
    exploits_df = pd.read_csv(f"{path}/files_exploits.csv")
    ids = exploits_df["id"]
    if delta is not None:
        present_ids = _get_ids_in_df(delta)
        ids = pd.concat([ids, present_ids])
        ids = ids.astype(int)
        ids.drop_duplicates(keep=False, inplace=True)

    return _fetch(ids, skip=skip)


def _get_ids_in_df(df):
    # First get all entrys of the df that are from exploitdb
    index = df["source"].str.startswith("https://www.exploit-db.com/exploits/")
    ids = df["source"][index].str.slice(start=len("https://www.exploit-db.com/exploits/"))
    return ids


def _fetch(ids, skip=None):
    """ids is an interable of ids in the exploit-db database
    Ignores all errors and just continues. The missing entrys can just be readded with a delta update.
    """
    # As the [offline copy]() of exploit-db.com does not contain cve mappings [1] we have to fetch them manually.
    # It is not documented why the offline copy misses CVE ids.
    # Another tool that fetches the information from the website is [cve_searchsploit](https://github.com/andreafioraldi/cve_searchsploit).
    # cve_searchsploit is unmaintained and the database they provide was last updated in 2020.
    #
    # [1] https://github.com/offensive-security/exploitdb/issues/150

    no_cve_df = DataFrame(columns=["id"])
    df = DataFrame(columns=["id", "cve"])
    for edb_id in ids:
        # Now lets use the undocumented API!
        # References: https://github.com/offensive-security/exploitdb/issues/219
        # TODO some entrys have a malformed cve id {'cve': 'CVE-cve‑2019‑5678', 'id': 46972}
        resp = requests.get(
            f"https://www.exploit-db.com/search?id={edb_id}",
            headers={
                # With the default we get a 403 response
                "User-Agent": "curl/7.68.0",
                "x-requested-with": "XMLHttpRequest",
            },
        )
        try:
            resp.raise_for_status()
        except requests.HTTPError:
            traceback.print_exc()
            continue

        try:
            json_resp = json.loads(resp.text)
        except json.JSONDecodeError:
            sys.stderr.write(f"Invalid json: {resp.text}")
            traceback.print_exc()
            continue

        cve = None
        # Whatever code means..
        for code in json_resp["data"][0]["code"]:
            if code["code_type"] != "cve":
                continue
            # There can be multiple cves for a single exploit
            cve = f"CVE-{code['code']}"
            df = pd.concat([df, DataFrame({"cve": cve, "id": edb_id}, index=[0])])
            sys.stderr.write(str({"cve": cve, "id": edb_id}) + "\n")

        if cve is None:
            sys.stderr.write(f"Adding {edb_id} to skip list")
            no_cve_df = no_cve_df.append([{"id": edb_id}])

    df["exploit-link"] = "https://www.exploit-db.com/download/" + df["id"].astype(str)
    df["source"] = "https://www.exploit-db.com/exploits/" + df["id"].astype(str)

    return df[["cve", "exploit-link", "source"]], no_cve_df
